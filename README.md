# ğŸ§ª AnÃ¡lisis Experimental A/B Test para E-commerce

## ğŸ“Œ Contexto del Negocio
En el entorno competitivo del comercio electrÃ³nico, cada cambio en la interfaz o en el sistema de recomendaciones representa una apuesta de negocio. Implementar modificaciones sin validaciÃ³n estadÃ­stica puede resultar en pÃ©rdidas significativas de conversiÃ³n o ticket promedio. Este proyecto responde a la necesidad de tomar decisiones basadas en evidencia cuantitativa antes de un despliegue masivo.

## ğŸ¯ Objetivo del Proyecto
Evaluar mediante un experimento A/B controlado si los cambios implementados en la interfaz y el sistema de recomendaciones de un e-commerce producen mejoras estadÃ­sticamente significativas en las mÃ©tricas clave de negocio:
- Validar el impacto sobre la **tasa de conversiÃ³n**.
- Medir el efecto sobre el **ticket promedio** por transacciÃ³n.
- Garantizar la **integridad del experimento** antes de interpretar resultados.
- Emitir una **recomendaciÃ³n estratÃ©gica** sustentada en evidencia cuantitativa.

## ğŸ” Alcance del AnÃ¡lisis
- **Nivel de anÃ¡lisis:** Usuario individual por grupo experimental (Control vs. Tratamiento).
- **Datos incluidos:** Registro de eventos de sesiÃ³n, conversiones y valor transaccional por grupo.
- **Supuestos:** Se asume asignaciÃ³n aleatoria correcta de usuarios a cada grupo y ausencia de contaminaciÃ³n entre variantes.

## ğŸ“Š Principales Insights del AnÃ¡lisis (EDA)
- **VerificaciÃ³n de Integridad:** Se auditÃ³ la distribuciÃ³n de usuarios entre grupos para confirmar la ausencia de sesgos en la asignaciÃ³n experimental.
- **DetecciÃ³n de AnomalÃ­as:** Se identificaron y trataron registros duplicados y sesiones con comportamiento atÃ­pico que podrÃ­an inflar artificialmente las mÃ©tricas.
- **DistribuciÃ³n de Conversiones:** AnÃ¡lisis de la tasa de conversiÃ³n por cohorte temporal para identificar posibles efectos de novedad o fatiga en el grupo de tratamiento.
- **AnÃ¡lisis de Varianza:** EvaluaciÃ³n de la dispersiÃ³n del ticket promedio entre grupos para seleccionar la prueba estadÃ­stica mÃ¡s adecuada.

## ğŸ¤– Enfoque AnalÃ­tico y Modelo
Se implementÃ³ un pipeline estadÃ­stico completo de validaciÃ³n experimental:

- **VerificaciÃ³n de integridad del experimento:** Control de tamaÃ±o de muestra y distribuciÃ³n entre grupos.
- **Limpieza y control de sesgos:** EliminaciÃ³n de registros contaminados o mal asignados.
- **Pruebas estadÃ­sticas aplicadas:**
  - **Test Z** â€” ComparaciÃ³n de proporciones de conversiÃ³n entre grupos.
  - **T-Test** â€” ComparaciÃ³n de medias del ticket promedio.
  - **ComparaciÃ³n de proporciones** â€” EvaluaciÃ³n de diferencias en mÃ©tricas binarias clave.
- **Control de errores:** EvaluaciÃ³n del tamaÃ±o del efecto y control de falsos positivos (error Tipo I).
- **InterpretaciÃ³n estratÃ©gica:** TraducciÃ³n de los resultados estadÃ­sticos a recomendaciones de negocio accionables.

## ğŸ“ˆ MÃ©tricas y Resultados
- **Tasa de ConversiÃ³n:** ComparaciÃ³n estadÃ­stica entre grupo control y tratamiento con nivel de significancia definido.
- **Ticket Promedio:** EvaluaciÃ³n del impacto econÃ³mico por transacciÃ³n entre variantes.
- **TamaÃ±o del Efecto:** CuantificaciÃ³n de la magnitud prÃ¡ctica del cambio, mÃ¡s allÃ¡ de la significancia estadÃ­stica.
- **ConclusiÃ³n:** Los resultados estadÃ­sticos validaron que los cambios en el embudo **no afectaron negativamente la conversiÃ³n**, mitigando riesgos financieros antes del despliegue total.

## ğŸ’¼ Impacto en Decisiones de Negocio
- **MitigaciÃ³n de Riesgo:** La validaciÃ³n previa al despliegue evita impactos negativos en mÃ©tricas de ingresos a escala completa.
- **Cultura Data-Driven:** Establece un framework replicable para evaluar futuras iteraciones de producto con rigor estadÃ­stico.
- **OptimizaciÃ³n de Producto:** Los hallazgos proveen una base sÃ³lida para priorizar el roadmap de mejoras de la interfaz con respaldo cuantitativo.

## ğŸ› ï¸ TecnologÃ­as y Herramientas Utilizadas
- **Lenguaje:** Python 3.x
- **LibrerÃ­as:** Pandas, NumPy, SciPy (Stats), Matplotlib, Seaborn
- **MÃ©todos estadÃ­sticos:** Z-Test, T-Test, ComparaciÃ³n de proporciones, AnÃ¡lisis de tamaÃ±o de efecto
- **Entorno de trabajo:** Jupyter Notebook, GitHub

## ğŸ“‚ Estructura del Repositorio
```
â”œâ”€â”€ data/
â”‚   â””â”€â”€ ab_test_data.csv          # Dataset del experimento A/B
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ ab_testing_ecommerce.ipynb  # Notebook principal del anÃ¡lisis
â”œâ”€â”€ README.md                       # DocumentaciÃ³n del proyecto
â””â”€â”€ requirements.txt                # Dependencias del entorno
```

## â–¶ï¸ CÃ³mo Ejecutar el Proyecto
1. Clonar el repositorio:
   ```
   git clone https://github.com/DiegoTascon94/ab-testing-ecommerce.git
   ```
2. Instalar dependencias:
   ```
   pip install -r requirements.txt
   ```
3. Abrir el anÃ¡lisis: Navegar a `/notebook` y ejecutar `ab_testing_ecommerce.ipynb`.

## ğŸ“ Conclusiones
Este proyecto demuestra que la toma de decisiones sobre cambios de producto no puede depender de la intuiciÃ³n. La aplicaciÃ³n de un framework experimental riguroso â€” que incluye verificaciÃ³n de integridad, control de sesgos y pruebas estadÃ­sticas mÃºltiples â€” permite separar el ruido del efecto real, protegiendo los ingresos del negocio y sustentando cada decisiÃ³n con evidencia cuantitativa.

## ğŸ”® PrÃ³ximos Pasos / Mejoras Futuras
- **Test Multivariante (MVT):** Extender el anÃ¡lisis para evaluar mÃºltiples variantes simultÃ¡neamente y optimizar la velocidad de iteraciÃ³n.
- **SegmentaciÃ³n de Resultados:** Desagregar el impacto del experimento por segmento de usuario (nuevo vs. recurrente, dispositivo, fuente de trÃ¡fico) para identificar efectos heterogÃ©neos.
- **AutomatizaciÃ³n del Framework:** Desarrollar un pipeline reutilizable que estandarice la evaluaciÃ³n estadÃ­stica de futuros experimentos A/B en la organizaciÃ³n. 
